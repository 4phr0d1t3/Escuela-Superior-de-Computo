{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"zUYQtrnzJJWI"},"source":["Sebastian Ruiz Uvalle\n","\n","6BV1\n","\n","Ing. en Inteligencia Artificial\n","\n","20 de junio de 2023\n","\n","Este programa genera lo modelos de clasificacion:\n"," - Regresión Logistica\n"," - Maquinas de Soporte Vectorial\n"," - Arboles de Decisión\n","\n","Usando el conjunto de datos de: https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":686},"id":"mtooM3PI-NMo","outputId":"680f2fcf-58d8-4e09-de40-038bb0e5456c"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-dd759bf6-eee6-412e-9c80-27265e98da81\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>ProductId</th>\n","      <th>UserId</th>\n","      <th>ProfileName</th>\n","      <th>HelpfulnessNumerator</th>\n","      <th>HelpfulnessDenominator</th>\n","      <th>Score</th>\n","      <th>Time</th>\n","      <th>Summary</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>B001E4KFG0</td>\n","      <td>A3SGXH7AUHU8GW</td>\n","      <td>delmartian</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>1303862400</td>\n","      <td>Good Quality Dog Food</td>\n","      <td>I have bought several of the Vitality canned d...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>B00813GRG4</td>\n","      <td>A1D87F6ZCVE5NK</td>\n","      <td>dll pa</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1346976000</td>\n","      <td>Not as Advertised</td>\n","      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>B000LQOCH0</td>\n","      <td>ABXLMWJIXXAIN</td>\n","      <td>Natalia Corres \"Natalia Corres\"</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1219017600</td>\n","      <td>\"Delight\" says it all</td>\n","      <td>This is a confection that has been around a fe...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>B000UA0QIQ</td>\n","      <td>A395BORC6FGVXV</td>\n","      <td>Karl</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>1307923200</td>\n","      <td>Cough Medicine</td>\n","      <td>If you are looking for the secret ingredient i...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>B006K2ZZ7K</td>\n","      <td>A1UQRSCLF8GW1T</td>\n","      <td>Michael D. Bigham \"M. Wassir\"</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>1350777600</td>\n","      <td>Great taffy</td>\n","      <td>Great taffy at a great price.  There was a wid...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd759bf6-eee6-412e-9c80-27265e98da81')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-dd759bf6-eee6-412e-9c80-27265e98da81 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-dd759bf6-eee6-412e-9c80-27265e98da81');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   Id   ProductId          UserId                      ProfileName  \\\n","0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n","1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n","2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n","3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n","4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n","\n","   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n","0                     1                       1      5  1303862400   \n","1                     0                       0      1  1346976000   \n","2                     1                       1      4  1219017600   \n","3                     3                       3      2  1307923200   \n","4                     0                       0      5  1350777600   \n","\n","                 Summary                                               Text  \n","0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n","1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n","2  \"Delight\" says it all  This is a confection that has been around a fe...  \n","3         Cough Medicine  If you are looking for the secret ingredient i...  \n","4            Great taffy  Great taffy at a great price.  There was a wid...  "]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","# Lectura del csv descargado de https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews\n","reviews = pd.read_csv(r'/content/drive/MyDrive/Reviews.csv')\n","\n","# Mostrado de la cabeza para analisis de los datos\n","reviews.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fw_fjEX9aPFT"},"outputs":[],"source":["# Eliminacion de las tuplas duplicadas con base en la columnta 'Text'\n","reviews_unique = reviews.drop_duplicates(subset=['Text'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aIyspLRt-vK3"},"outputs":[],"source":["# Crea un nuevo DataFrame vacío llamado 'aux'.\n","aux = pd.DataFrame()\n","\n","# Pasado a un DataFrame auxiliar para solo operar con las columnas que nos importan\n","aux['Summary'] = reviews_unique['Summary']\n","aux['Text'] = reviews_unique['Text']\n","aux['HelpfulnessNumerator'] = reviews_unique['HelpfulnessNumerator']\n","aux['HelpfulnessDenominator'] = reviews_unique['HelpfulnessDenominator']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"id":"ojk6vf_7AHVd","outputId":"1efa17f2-3991-4665-b5c7-02499ac27692"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-f0e32471-1433-493b-bbd7-c7b285ce587d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Summary</th>\n","      <th>Text</th>\n","      <th>HelpfulnessNumerator</th>\n","      <th>HelpfulnessDenominator</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Good Quality Dog Food</td>\n","      <td>I have bought several of the Vitality canned d...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Not as Advertised</td>\n","      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>\"Delight\" says it all</td>\n","      <td>This is a confection that has been around a fe...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Cough Medicine</td>\n","      <td>If you are looking for the secret ingredient i...</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Great taffy</td>\n","      <td>Great taffy at a great price.  There was a wid...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0e32471-1433-493b-bbd7-c7b285ce587d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f0e32471-1433-493b-bbd7-c7b285ce587d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f0e32471-1433-493b-bbd7-c7b285ce587d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 Summary                                               Text  \\\n","0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n","1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n","2  \"Delight\" says it all  This is a confection that has been around a fe...   \n","3         Cough Medicine  If you are looking for the secret ingredient i...   \n","4            Great taffy  Great taffy at a great price.  There was a wid...   \n","\n","   HelpfulnessNumerator  HelpfulnessDenominator Sentiment  \n","0                     1                       1  Positive  \n","1                     0                       0  Negative  \n","2                     1                       1  Positive  \n","3                     3                       3  Negative  \n","4                     0                       0  Positive  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Esta función devuelve el valor asignado correspondiente al número de fila dado.\n","# Parámetros:\n","        # row_number: número de fila\n","        # assigned_value: diccionario con los valores asignados\n","# Retorna el valor asignado para la fila especificada.\n","def set_value(row_number, assigned_value):\n","    return assigned_value[row_number]\n","\n","# Diccionario que mapea los valores de 'Score' a etiquetas de sentimiento.\n","sentimentDictionary = {\n","    1: 'Negative', 2: 'Negative',\n","    3: 'Neutral',\n","    4: 'Positive', 5: 'Positive'\n","}\n","\n","# Se aplica la función 'set_value()' a la columna 'Score' del DataFrame 'reviews_unique',\n","# utilizando el diccionario 'sentimentDictionary' para asignar etiquetas de sentimiento a los valores de 'Score'.\n","# El resultado se guarda en una nueva columna llamada 'Sentiment' en el DataFrame 'aux'.\n","aux['Sentiment'] = reviews_unique['Score'].apply(set_value, args=(sentimentDictionary, ))\n","\n","aux.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j4Do7eKiGJXn","outputId":"b15111ae-6f4c-4bd5-cfd4-dbeead7ccf6d"},"outputs":[{"data":{"text/plain":["Positive    306758\n","Negative     57067\n","Neutral      29754\n","Name: Sentiment, dtype: int64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Calcula el recuento de cada valor único en la columna 'Sentiment' del DataFrame 'aux'.\n","# Esto proporciona información sobre la distribución de los sentimientos en los datos.\n","aux['Sentiment'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x6VqBp7kHuo-","outputId":"f122c885-7495-4f53-db58-ebbadfd42560"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-6-28d0155e9ab9>:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  aux = aux.append(neutral_rows, ignore_index=True)\n"]}],"source":["# Crea un nuevo DataFrame vacío llamado 'neutral_rows'.\n","neutral_rows = pd.DataFrame()\n","\n","# Filtra las filas del DataFrame 'aux' donde el valor de la columna 'Sentiment' es igual a 'Neutral'.\n","neutral_rows = aux[aux['Sentiment'] == 'Neutral']\n","# Agrega las filas filtradas al DataFrame 'aux' utilizando el método 'append()'.\n","# La opción 'ignore_index=True' asegura que se generen nuevos índices para las filas agregadas.\n","aux = aux.append(neutral_rows, ignore_index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gPmQv-mxLJqy","outputId":"2e0b5dc0-b046-4620-b0ee-20a9dfe5b08b"},"outputs":[{"data":{"text/plain":["Positive    306758\n","Neutral      59508\n","Negative     57067\n","Name: Sentiment, dtype: int64"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Calcula el recuento de cada valor único en la columna 'Sentiment' del DataFrame 'aux'.\n","# Esto proporciona información sobre la distribución de los sentimientos en los datos.\n","aux['Sentiment'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPlpqerubRMK"},"outputs":[],"source":["# Filtra las filas del DataFrame 'aux' para seleccionar solo aquellas con el valor 'Positive' en la columna 'Sentiment'.\n","positive_df = aux[aux['Sentiment'] == 'Positive']\n","\n","# El comentario de abajo fue para poder reanudar la codificacion desde el uso de este csv\n","#positive_df.to_csv('positive_sentiment.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"14B6gUzJijse"},"outputs":[],"source":["# Ordena el DataFrame 'positive_df' en función de las columnas 'HelpfulnessNumerator' y 'HelpfulnessDenominator'\n","# en orden descendente. Esto permite priorizar los registros con mayor valor de 'HelpfulnessNumerator'\n","# y 'HelpfulnessDenominator', lo que puede indicar una mayor utilidad de las reseñas .\n","sorted_reviews = positive_df.sort_values(by=['HelpfulnessNumerator', 'HelpfulnessDenominator'], ascending=False)\n","\n","# Selecciona las primeras 60000 filas del DataFrame ordenado y sobrescribe el DataFrame 'positive_df' con ellas.\n","# Al hacer esto, se obtiene un subconjunto de las reseñas positivas más relevantes y útiles, que puede ser más manejable\n","# para análisis o visualización posteriores.\n","positive_df = sorted_reviews.head(60000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ShXNWBFdkEoE"},"outputs":[],"source":["# Define una lista llamada 'columns_of_interest' que contiene los nombres de las columnas que se desea seleccionar.\n","columns_of_interest = ['Summary','Text','Sentiment']\n","\n","# Crea un nuevo DataFrame llamado 'df' para almacenar las filas que cumplen con cierta condición.\n","df = pd.DataFrame()\n","\n","# Filtra las filas del DataFrame 'aux' donde el valor de la columna 'Sentiment' es igual a 'Negative',\n","# y selecciona solo las columnas de interés especificadas en la lista 'columns_of_interest'.\n","# La función 'copy()' se utiliza para realizar una copia de las filas seleccionadas en un nuevo DataFrame 'df'.\n","# Esto permite obtener un subconjunto de las filas con sentimiento negativo y solo las columnas de interés,\n","# que puede ser útil para análisis o visualización específicos.\n","df = aux.loc[aux['Sentiment'] == 'Negative', columns_of_interest].copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0GWqdGczkjOE"},"outputs":[],"source":["# Crea un nuevo DataFrame llamado 'neutral_df' para almacenar las filas que cumplen con cierta condición.\n","neutral_df = pd.DataFrame()\n","\n","# Filtra las filas del DataFrame 'aux' donde el valor de la columna 'Sentiment' es igual a 'Neutral',\n","# y selecciona solo las columnas de interés especificadas en la lista 'columns_of_interest'.\n","# La función 'copy()' se utiliza para realizar una copia de las filas seleccionadas en un nuevo DataFrame 'neutral_df'.\n","# Esto permite obtener un subconjunto de las filas con sentimiento neutral y solo las columnas de interés,\n","# que puede ser útil para análisis o visualización específicos.\n","neutral_df = aux.loc[aux['Sentiment'] == 'Neutral', columns_of_interest].copy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JpfYGfDVk50B"},"outputs":[],"source":["# Concatena verticalmente (une por filas) los DataFrames 'df' y 'neutral_df',\n","# y sobrescribe el resultado en el DataFrame 'df'.\n","df = pd.concat([df, neutral_df])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W5uMtnnSqRxD"},"outputs":[],"source":["# Concatena verticalmente (une por filas) los DataFrames 'df' y 'positive_df' utilizando las columnas de interés especificadas en 'columns_of_interest',\n","# y sobrescribe el resultado en el DataFrame 'df'.\n","df = pd.concat([df, positive_df[columns_of_interest]])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3n0r5H7k_fy","outputId":"68b1364b-1ecb-4c06-bc7a-af01b690828c"},"outputs":[{"data":{"text/plain":["Positive    60000\n","Neutral     59508\n","Negative    57067\n","Name: Sentiment, dtype: int64"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Calcula el recuento de cada valor único en la columna 'Sentiment' del DataFrame 'df'.\n","# Esto proporciona información sobre la distribución de los sentimientos en los datos filtrados.\n","df['Sentiment'].value_counts()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nsnYcV9-rJIk"},"outputs":[],"source":["# Guarda el DataFrame 'df' en un archivo CSV llamado 'data.csv' sin incluir el índice en la salida.\n","df.to_csv('data.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"SE0tz0l291py","outputId":"1a6842d0-026e-4f73-885c-fb4bd3f1943a"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-17f66eed-4279-4b4c-bc7e-3f93b934ebaa\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Summary</th>\n","      <th>Text</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Not as Advertised</td>\n","      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Cough Medicine</td>\n","      <td>If you are looking for the secret ingredient i...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>My Cats Are Not Fans of the New Food</td>\n","      <td>My cats have been happily eating Felidae Plati...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>poor taste</td>\n","      <td>I love eating them and they are good for watch...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Nasty No flavor</td>\n","      <td>The candy is just red , No flavor . Just  plan...</td>\n","      <td>Negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17f66eed-4279-4b4c-bc7e-3f93b934ebaa')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-17f66eed-4279-4b4c-bc7e-3f93b934ebaa button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-17f66eed-4279-4b4c-bc7e-3f93b934ebaa');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                Summary  \\\n","0                     Not as Advertised   \n","1                        Cough Medicine   \n","2  My Cats Are Not Fans of the New Food   \n","3                            poor taste   \n","4                       Nasty No flavor   \n","\n","                                                Text Sentiment  \n","0  Product arrived labeled as Jumbo Salted Peanut...  Negative  \n","1  If you are looking for the secret ingredient i...  Negative  \n","2  My cats have been happily eating Felidae Plati...  Negative  \n","3  I love eating them and they are good for watch...  Negative  \n","4  The candy is just red , No flavor . Just  plan...  Negative  "]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["# Lee los datos desde un archivo CSV llamado 'data.csv' ubicado en la ruta \"/content/drive/MyDrive/\"\n","# y los carga en un nuevo DataFrame llamado 'data'.\n","data = pd.read_csv(r'/content/drive/MyDrive/data.csv')\n","\n","# Muestra las primeras filas del DataFrame 'data'.\n","data.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DKntk7x9-C6l","outputId":"47907ea7-d119-47a8-ec35-da18263602a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["0         not as advertised product arrived labeled as j...\n","1         cough medicine if you are looking for the secr...\n","2         my cats are not fans of the new food my cats h...\n","3         poor taste i love eating them and they are goo...\n","4         nasty no flavor the candy is just red , no fla...\n","                                ...                        \n","176570    women's bean project oatmeal choc chip cookie ...\n","176571    for all butter lovers. this is a intensed cris...\n","176572    love these cookies!!! these cookies were recom...\n","176573    best love it very much. too bad this item is n...\n","176574    seriously good, but needs more cheese! well, i...\n","Name: SummaryText, Length: 176575, dtype: object\n"]}],"source":["# Combina las columnas 'Summary' y 'Text' como cadenas de texto en una nueva columna llamada 'SummaryText'.\n","data['SummaryText'] = data['Summary'].astype(str) + ' ' + data['Text'].astype(str)\n","\n","# Convierte todas las cadenas de la columna 'SummaryText' a minúsculas.\n","data['SummaryText'] = data['SummaryText'].str.lower()\n","\n","# Imprime los valores de la columna 'SummaryText'.\n","print(data['SummaryText'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EzB-DWWgu-EQ"},"outputs":[],"source":["# Importa las bibliotecas necesarias de NLTK (Natural Language Toolkit).\n","import nltk\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","\n","# Descarga los recursos necesarios para el tokenizador de NLTK.\n","nltk.download('punkt')\n","\n","# Inicializa el stemmer de Porter.\n","stemmer = PorterStemmer()\n","\n","# Crea una lista vacía para almacenar los textos procesados mediante stemming.\n","stemmed_dataset = []\n","\n","# Itera sobre cada texto en la columna 'SummaryText' del DataFrame 'data'.\n","for text in data['SummaryText']:\n","    # Tokeniza el texto en palabras y las convierte a minúsculas.\n","    tokens = word_tokenize(text.lower())\n","    # Realiza stemming en cada palabra del texto utilizando el stemmer de Porter.\n","    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n","    # Une las palabras procesadas mediante stemming en un solo texto.\n","    stemmed_text = ' '.join(stemmed_tokens)\n","    # Agrega el texto procesado a la lista de 'stemmed_dataset'.\n","    stemmed_dataset.append(stemmed_text)\n","\n","# Imprime un mensaje indicando que 'stemmed_dataset' está listo.\n","# print(\"stemmed_dataset ready\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"id":"GsJqnhtWzKk5","outputId":"57a2c17f-58be-4654-d88b-a3d7c4b8c6ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Negative' 'Neutral' 'Positive']\n"]},{"data":{"text/html":["\n","  <div id=\"df-e10213bf-8af2-4cfa-a1aa-31d8073c3adc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>not as advertis product arriv label as jumbo s...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cough medicin if you are look for the secret i...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my cat are not fan of the new food my cat have...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>poor tast i love eat them and they are good fo...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>nasti no flavor the candi is just red , no fla...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>176570</th>\n","      <td>women 's bean project oatmeal choc chip cooki ...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>176571</th>\n","      <td>for all butter lover . thi is a intens crisp b...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>176572</th>\n","      <td>love these cooki ! ! ! these cooki were recomm...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>176573</th>\n","      <td>best love it veri much . too bad thi item is n...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>176574</th>\n","      <td>serious good , but need more chees ! well , i ...</td>\n","      <td>Positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>176575 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e10213bf-8af2-4cfa-a1aa-31d8073c3adc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e10213bf-8af2-4cfa-a1aa-31d8073c3adc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e10213bf-8af2-4cfa-a1aa-31d8073c3adc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                     Text Sentiment\n","0       not as advertis product arriv label as jumbo s...  Negative\n","1       cough medicin if you are look for the secret i...  Negative\n","2       my cat are not fan of the new food my cat have...  Negative\n","3       poor tast i love eat them and they are good fo...  Negative\n","4       nasti no flavor the candi is just red , no fla...  Negative\n","...                                                   ...       ...\n","176570  women 's bean project oatmeal choc chip cooki ...  Positive\n","176571  for all butter lover . thi is a intens crisp b...  Positive\n","176572  love these cooki ! ! ! these cooki were recomm...  Positive\n","176573  best love it veri much . too bad thi item is n...  Positive\n","176574  serious good , but need more chees ! well , i ...  Positive\n","\n","[176575 rows x 2 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# Crea un nuevo DataFrame 'df_stemming' utilizando los textos procesados por stemming.\n","df_stemming = pd.DataFrame(stemmed_dataset)\n","\n","# Asigna la columna 'Sentiment' del DataFrame original 'data' a la columna 'Sentiment' del DataFrame 'df_stemming'.\n","df_stemming['Sentiment'] = data['Sentiment']\n","\n","# Imprime los valores únicos de la columna 'Sentiment' en 'df_stemming'.\n","print(df_stemming[\"Sentiment\"].unique())\n","\n","# Renombra la columna '0' a 'Text' en 'df_stemming'.\n","df_stemming.rename(columns={0: 'Text'}, inplace=True)\n","\n","# Muestra el DataFrame 'df_stemming'.\n","df_stemming\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xLTXqmqb0aUQ"},"outputs":[],"source":["# Guarda el DataFrame 'df_stemming' en un archivo CSV llamado 'stemming.csv' sin incluir el índice en la salida.\n","df_stemming.to_csv('stemming.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"La30cHuuvPdE","outputId":"9b482ea0-4661-45fa-9e17-3d14faeefb6f"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["# Importa las bibliotecas necesarias de NLTK.\n","from nltk.stem import WordNetLemmatizer\n","\n","# Descarga los recursos necesarios para la lematización.\n","nltk.download('wordnet')\n","\n","# Inicializa el lematizador de WordNet.\n","lemmatizer = WordNetLemmatizer()\n","\n","# Crea una lista vacía para almacenar los textos lematizados.\n","lemmatized_dataset = []\n","\n","# Itera sobre cada texto en la columna 'SummaryText' del DataFrame 'data'.\n","for text in data['SummaryText']:\n","    # Tokeniza el texto en palabras y las convierte a minúsculas.\n","    tokens = word_tokenize(text.lower())\n","    # Realiza la lematización en cada palabra del texto utilizando el lematizador de WordNet.\n","    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n","    # Une las palabras lematizadas en un solo texto.\n","    lemmatized_text = ' '.join(lemmatized_tokens)\n","    # Agrega el texto lematizado a la lista de 'lemmatized_dataset'.\n","    lemmatized_dataset.append(lemmatized_text)\n","\n","# Imprime un mensaje indicando que 'lemmatized_dataset' está listo.\n","# print(\"lemmatized_dataset ready\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"id":"qXrbqg8w5uRt","outputId":"b9025eb2-27d1-4c3c-cc74-1e2c24a343b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Negative' 'Neutral' 'Positive']\n"]},{"data":{"text/html":["\n","  <div id=\"df-65fd7e16-2472-45bd-bf66-acf90364830e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>not a advertised product arrived labeled a jum...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cough medicine if you are looking for the secr...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my cat are not fan of the new food my cat have...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>poor taste i love eating them and they are goo...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>nasty no flavor the candy is just red , no fla...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>176570</th>\n","      <td>woman 's bean project oatmeal choc chip cookie...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>176571</th>\n","      <td>for all butter lover . this is a intensed cris...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>176572</th>\n","      <td>love these cooky ! ! ! these cooky were recomm...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>176573</th>\n","      <td>best love it very much . too bad this item is ...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>176574</th>\n","      <td>seriously good , but need more cheese ! well ,...</td>\n","      <td>Positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>176575 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65fd7e16-2472-45bd-bf66-acf90364830e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-65fd7e16-2472-45bd-bf66-acf90364830e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-65fd7e16-2472-45bd-bf66-acf90364830e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                     Text Sentiment\n","0       not a advertised product arrived labeled a jum...  Negative\n","1       cough medicine if you are looking for the secr...  Negative\n","2       my cat are not fan of the new food my cat have...  Negative\n","3       poor taste i love eating them and they are goo...  Negative\n","4       nasty no flavor the candy is just red , no fla...  Negative\n","...                                                   ...       ...\n","176570  woman 's bean project oatmeal choc chip cookie...  Positive\n","176571  for all butter lover . this is a intensed cris...  Positive\n","176572  love these cooky ! ! ! these cooky were recomm...  Positive\n","176573  best love it very much . too bad this item is ...  Positive\n","176574  seriously good , but need more cheese ! well ,...  Positive\n","\n","[176575 rows x 2 columns]"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# Crea un nuevo DataFrame 'df_lematization' utilizando los textos lematizados.\n","df_lematization = pd.DataFrame(lemmatized_dataset)\n","\n","# Asigna la columna 'Sentiment' del DataFrame original 'data' a la columna 'Sentiment' del DataFrame 'df_lematization'.\n","df_lematization['Sentiment'] = data['Sentiment']\n","\n","# Imprime los valores únicos de la columna 'Sentiment' en 'df_lematization'.\n","print(df_lematization[\"Sentiment\"].unique())\n","\n","# Renombra la columna '0' a 'Text' en 'df_lematization'.\n","df_lematization.rename(columns={0: 'Text'}, inplace=True)\n","\n","# Muestra el DataFrame 'df_lematization'.\n","df_lematization\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AzzVba7a6Pg5"},"outputs":[],"source":["# Guarda el DataFrame 'df_lematization' en un archivo CSV llamado 'lematization.csv' sin incluir el índice en la salida.\n","df_lematization.to_csv('lematization.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jx1YCG1x7z1S","outputId":"e4268fec-426f-441a-b962-541a4e38a5af"},"outputs":[{"name":"stdout","output_type":"stream","text":["both_dataset ready\n"]}],"source":["# import nltk\n","# from nltk.stem import PorterStemmer, WordNetLemmatizer\n","\n","# nltk.download('punkt')\n","# nltk.download('wordnet')\n","\n","# Inicializa el stemmer de Porter y el lematizador de WordNet.\n","stemmer = PorterStemmer()\n","lemmatizer = WordNetLemmatizer()\n","\n","# Crea una lista vacía para almacenar los textos procesados tanto por stemming como por lematización.\n","both_dataset = []\n","\n","# Itera sobre cada texto en la columna 'SummaryText' del DataFrame 'data'.\n","for text in data['SummaryText']:\n","    # Tokeniza el texto en palabras y las convierte a minúsculas.\n","    tokens = word_tokenize(text.lower())\n","    # Realiza el stemming en cada palabra del texto utilizando el stemmer de Porter.\n","    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n","    # Realiza la lematización en cada palabra stemizada utilizando el lematizador de WordNet.\n","    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in stemmed_tokens]\n","    # Une las palabras lematizadas en un solo texto.\n","    processed_text = ' '.join(lemmatized_tokens)\n","    # Agrega el texto procesado a la lista 'both_dataset'.\n","    both_dataset.append(processed_text)\n","\n","# Imprime un mensaje indicando que 'both_dataset' está listo.\n","print(\"both_dataset ready\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"id":"8dvbaE8n8V_8","outputId":"a8b3939f-e2b4-438d-b3b0-db7b94206010"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Negative' 'Neutral' 'Positive']\n"]},{"data":{"text/html":["\n","  <div id=\"df-709be542-0447-44d8-a138-de8f24e2165a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>not a advertis product arriv label a jumbo sal...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cough medicin if you are look for the secret i...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my cat are not fan of the new food my cat have...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>poor tast i love eat them and they are good fo...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>nasti no flavor the candi is just red , no fla...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>176570</th>\n","      <td>woman 's bean project oatmeal choc chip cooki ...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>176571</th>\n","      <td>for all butter lover . thi is a intens crisp b...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>176572</th>\n","      <td>love these cooki ! ! ! these cooki were recomm...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>176573</th>\n","      <td>best love it veri much . too bad thi item is n...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>176574</th>\n","      <td>serious good , but need more chees ! well , i ...</td>\n","      <td>Positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>176575 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-709be542-0447-44d8-a138-de8f24e2165a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-709be542-0447-44d8-a138-de8f24e2165a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-709be542-0447-44d8-a138-de8f24e2165a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                     Text Sentiment\n","0       not a advertis product arriv label a jumbo sal...  Negative\n","1       cough medicin if you are look for the secret i...  Negative\n","2       my cat are not fan of the new food my cat have...  Negative\n","3       poor tast i love eat them and they are good fo...  Negative\n","4       nasti no flavor the candi is just red , no fla...  Negative\n","...                                                   ...       ...\n","176570  woman 's bean project oatmeal choc chip cooki ...  Positive\n","176571  for all butter lover . thi is a intens crisp b...  Positive\n","176572  love these cooki ! ! ! these cooki were recomm...  Positive\n","176573  best love it veri much . too bad thi item is n...  Positive\n","176574  serious good , but need more chees ! well , i ...  Positive\n","\n","[176575 rows x 2 columns]"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# Crea un nuevo DataFrame 'df_both' utilizando los textos procesados tanto por stemming como por lematización.\n","df_both = pd.DataFrame(both_dataset)\n","\n","# Asigna la columna 'Sentiment' del DataFrame original 'data' a la columna 'Sentiment' del DataFrame 'df_both'.\n","df_both['Sentiment'] = data['Sentiment']\n","\n","# Imprime los valores únicos de la columna 'Sentiment' en 'df_both'.\n","print(df_both[\"Sentiment\"].unique())\n","\n","# Renombra la columna '0' a 'Text' en 'df_both'.\n","df_both.rename(columns={0: 'Text'}, inplace=True)\n","\n","# Muestra el DataFrame 'df_both'.\n","df_both\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1d6XIv9Y-o-I"},"outputs":[],"source":["# Guarda el DataFrame 'df_both' en un archivo CSV llamado 'both.csv' sin incluir el índice en la salida.\n","df_both.to_csv('both.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"id":"YHuOh6V7_R8b","outputId":"fec980fd-1295-4716-90c1-0a26fb79e9ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Negative' 'Neutral' 'Positive']\n"]},{"data":{"text/html":["\n","  <div id=\"df-1c45a0db-0599-42af-82f8-0c0ce1e47f39\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>not a advertis product arriv label a jumbo sal...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cough medicin if you are look for the secret i...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my cat are not fan of the new food my cat have...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>poor tast i love eat them and they are good fo...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>nasti no flavor the candi is just red , no fla...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>176570</th>\n","      <td>woman 's bean project oatmeal choc chip cooki ...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>176571</th>\n","      <td>for all butter lover . thi is a intens crisp b...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>176572</th>\n","      <td>love these cooki ! ! ! these cooki were recomm...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>176573</th>\n","      <td>best love it veri much . too bad thi item is n...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>176574</th>\n","      <td>serious good , but need more chees ! well , i ...</td>\n","      <td>Positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>176575 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c45a0db-0599-42af-82f8-0c0ce1e47f39')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1c45a0db-0599-42af-82f8-0c0ce1e47f39 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1c45a0db-0599-42af-82f8-0c0ce1e47f39');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                     Text Sentiment\n","0       not a advertis product arriv label a jumbo sal...  Negative\n","1       cough medicin if you are look for the secret i...  Negative\n","2       my cat are not fan of the new food my cat have...  Negative\n","3       poor tast i love eat them and they are good fo...  Negative\n","4       nasti no flavor the candi is just red , no fla...  Negative\n","...                                                   ...       ...\n","176570  woman 's bean project oatmeal choc chip cooki ...  Positive\n","176571  for all butter lover . thi is a intens crisp b...  Positive\n","176572  love these cooki ! ! ! these cooki were recomm...  Positive\n","176573  best love it veri much . too bad thi item is n...  Positive\n","176574  serious good , but need more chees ! well , i ...  Positive\n","\n","[176575 rows x 2 columns]"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["# Crea un nuevo DataFrame 'df_none' con las columnas 'Text' y 'Sentiment' del DataFrame original 'data'.\n","df_none = pd.DataFrame()\n","df_none['Text'] = data['SummaryText']\n","df_none['Sentiment'] = data['Sentiment']\n","\n","# Imprime los valores únicos de la columna 'Sentiment' en 'df_both'.\n","print(df_both[\"Sentiment\"].unique())\n","\n","# Muestra el DataFrame 'df_both'.\n","df_both\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1bPMWw7o_ruN"},"outputs":[],"source":["# Guarda el DataFrame 'df_none' en un archivo CSV llamado 'none.csv' sin incluir el índice en la salida.\n","df_none.to_csv('none.csv', index=False)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14215,"status":"ok","timestamp":1687315267070,"user":{"displayName":"Sebastian Ruiz Uvalle","userId":"09308680691368063451"},"user_tz":360},"id":"PoW-cPJ401dA","outputId":"14ea5bb2-ad54-4621-b54d-1beb7379ab42"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Importa la biblioteca necesaria para montar Google Drive en Google Colab.\n","from google.colab import drive\n","\n","# Monta Google Drive en el entorno de Colab.\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7403,"status":"ok","timestamp":1687318196050,"user":{"displayName":"Sebastian Ruiz Uvalle","userId":"09308680691368063451"},"user_tz":360},"id":"9uqFMuaeATKw","outputId":"2328702b-8a74-4fff-b95b-b24e77d2ca9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                Text Sentiment\n","0  not as advertised product arrived labeled as j...  Negative\n","1  cough medicine if you are looking for the secr...  Negative\n","2  my cats are not fans of the new food my cats h...  Negative\n","3  poor taste i love eating them and they are goo...  Negative\n","4  nasty no flavor the candy is just red , no fla...  Negative\n","                                                Text Sentiment\n","0  not as advertis product arriv label as jumbo s...  Negative\n","1  cough medicin if you are look for the secret i...  Negative\n","2  my cat are not fan of the new food my cat have...  Negative\n","3  poor tast i love eat them and they are good fo...  Negative\n","4  nasti no flavor the candi is just red , no fla...  Negative\n","                                                Text Sentiment\n","0  not a advertised product arrived labeled a jum...  Negative\n","1  cough medicine if you are looking for the secr...  Negative\n","2  my cat are not fan of the new food my cat have...  Negative\n","3  poor taste i love eating them and they are goo...  Negative\n","4  nasty no flavor the candy is just red , no fla...  Negative\n","                                                Text Sentiment\n","0  not a advertis product arriv label a jumbo sal...  Negative\n","1  cough medicin if you are look for the secret i...  Negative\n","2  my cat are not fan of the new food my cat have...  Negative\n","3  poor tast i love eat them and they are good fo...  Negative\n","4  nasti no flavor the candi is just red , no fla...  Negative\n"]}],"source":["# Importa la biblioteca pandas para trabajar con datos tabulares.\n","import pandas as pd\n","\n","# Lee los archivos CSV correspondientes a los DataFrames df_none, df_stemming, df_lematization y df_both.\n","# df_none = pd.read_csv(r'none.csv')\n","# df_stemming = pd.read_csv(r'stemming.csv')\n","# df_lematization = pd.read_csv(r'lematization.csv')\n","# df_both = pd.read_csv(r'both.csv')\n","\n","df_none = pd.read_csv(r'/content/drive/MyDrive/none.csv')\n","df_stemming = pd.read_csv(r'/content/drive/MyDrive/stemming.csv')\n","df_lematization = pd.read_csv(r'/content/drive/MyDrive/lematization.csv')\n","df_both = pd.read_csv(r'/content/drive/MyDrive/both.csv')\n","\n","# Imprime las primeras filas de cada DataFrame para verificar la carga de datos.\n","print(df_none.head())\n","print(df_stemming.head())\n","print(df_lematization.head())\n","print(df_both.head())\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1206,"status":"ok","timestamp":1687318201190,"user":{"displayName":"Sebastian Ruiz Uvalle","userId":"09308680691368063451"},"user_tz":360},"id":"vu7cG2ASgkJl"},"outputs":[],"source":["# Importa la clase LabelEncoder de scikit-learn para codificar las etiquetas de sentimiento.\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Crea una instancia de LabelEncoder.\n","label_encoder = LabelEncoder()\n","\n","# Codifica las etiquetas de sentimiento en los DataFrames df_none, df_stemming, df_lematization y df_both.\n","df_none['Sentiment'] = label_encoder.fit_transform(df_none['Sentiment'])\n","df_stemming['Sentiment'] = label_encoder.fit_transform(df_stemming['Sentiment'])\n","df_lematization['Sentiment'] = label_encoder.fit_transform(df_lematization['Sentiment'])\n","df_both['Sentiment'] = label_encoder.fit_transform(df_both['Sentiment'])"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":324,"status":"ok","timestamp":1687318201941,"user":{"displayName":"Sebastian Ruiz Uvalle","userId":"09308680691368063451"},"user_tz":360},"id":"txDVznkIgkJm"},"outputs":[],"source":["# Importa la función train_test_split de scikit-learn para dividir los conjuntos de datos.\n","from sklearn.model_selection import train_test_split\n","\n","# Divide los conjunto de datos en conjuntos de entrenamiento y prueba.\n","X_none_train, X_none_test, y_none_train, y_none_test = train_test_split(df_none['Text'], df_none['Sentiment'], random_state = 0, test_size=0.2)\n","X_stemming_train, X_stemming_test, y_stemming_train, y_stemming_test = train_test_split(df_stemming['Text'], df_stemming['Sentiment'], random_state = 0, test_size=0.2)\n","X_lematization_train, X_lematization_test, y_lematization_train, y_lematization_test = train_test_split(df_lematization['Text'], df_lematization['Sentiment'], random_state = 0, test_size=0.2)\n","X_both_train, X_both_test, y_both_train, y_both_test = train_test_split(df_both['Text'], df_both['Sentiment'], random_state = 0, test_size=0.2)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84074,"status":"ok","timestamp":1687315376550,"user":{"displayName":"Sebastian Ruiz Uvalle","userId":"09308680691368063451"},"user_tz":360},"id":"e6I4fKPvCqiH","outputId":"a41e0934-7313-4864-ace9-42e05a595826"},"outputs":[{"name":"stdout","output_type":"stream","text":["Vectorizacion terminada\n"]}],"source":["import tensorflow as tf\n","\n","# Importa la clase TfidfVectorizer de scikit-learn para realizar la vectorización TF-IDF.\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Definir la función para aplicar la vectorización TF-IDF a los conjuntos de datos de texto.\n","def tfidf_ngram(X_train, X_test):\n","\t# Crea una instancia de TfidfVectorizer.\n","\tvectorizer = TfidfVectorizer()\n"," # Aplica la vectorización TF-IDF a los conjuntos de entrenamiento y prueba.\n","\twith tf.device('/gpu:0'): # Utiliza la GPU para acelerar el procesamiento si está disponible.\n","\t\tx_train_vec = vectorizer.fit_transform(X_train)\n","\t\tx_test_vec = vectorizer.transform(X_test)\n","\treturn x_train_vec,x_test_vec\n","\n","# Aplicando la vectorizacion TF-IDF a los textos\n","X_tfidf_none_train, X_tfidf_none_test = tfidf_ngram(X_train=X_none_train,X_test=X_none_test)\n","X_tfidf_stemming_train, X_tfidf_stemming_test = tfidf_ngram(X_train=X_stemming_train,X_test=X_stemming_test)\n","X_tfidf_lematization_train, X_tfidf_lematization_test = tfidf_ngram(X_train=X_lematization_train,X_test=X_lematization_test)\n","X_tfidf_both_train, X_tfidf_both_test = tfidf_ngram(X_train=X_both_train,X_test=X_both_test)\n","\n","print(\"Vectorizacion terminada\")\n","\n","# print(X_tfidf_none_train)\n","# print(X_tfidf_none_test)\n","\n","# print(X_tfidf_stemming_train)\n","# print(X_tfidf_stemming_test)\n","\n","# print(X_tfidf_lematization_train)\n","# print(X_tfidf_lematization_test)\n","\n","# print(X_tfidf_both_train)\n","# print(X_tfidf_both_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JBQTiY3VgkJm","outputId":"2f42108c-c9b6-4141-99e8-3e1ffa49c6a7"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Aphrodite\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model Name</th>\n","      <th>DataFrame</th>\n","      <th>Cross Validation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression</td>\n","      <td>none</td>\n","      <td>0.741951</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>LogisticRegression</td>\n","      <td>stemming</td>\n","      <td>0.733003</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>LogisticRegression</td>\n","      <td>lematization</td>\n","      <td>0.738015</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>LogisticRegression</td>\n","      <td>both</td>\n","      <td>0.732125</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           Model Name     DataFrame  Cross Validation\n","0  LogisticRegression          none          0.741951\n","1  LogisticRegression      stemming          0.733003\n","2  LogisticRegression  lematization          0.738015\n","3  LogisticRegression          both          0.732125"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Importa las clases de los modelos y funciones relacionadas de scikit-learn.\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import cross_val_score\n","\n","# Crea un diccionario que contiene los datos de texto vectorizados para cada tipo de procesamiento de texto.\n","text_embedding = {\n","\t'none':(X_tfidf_none_train, X_tfidf_none_test, y_none_train, y_none_test),\n","\t'stemming':(X_tfidf_stemming_train, X_tfidf_stemming_test, y_stemming_train, y_stemming_test),\n","\t'lematization':(X_tfidf_lematization_train, X_tfidf_lematization_test, y_lematization_train, y_lematization_test),\n","\t'both':(X_tfidf_both_train, X_tfidf_both_test, y_both_train, y_both_test)\n","}\n","\n","# Crea una lista de modelos a entrenar y evaluar, cabe mencionar que se intento hacer el proceso iterable pero\n","#  se opto por hacerlo por separado ya que  tardaban mucho en entrenarse y evaluarlos\n","models = [\n","\tLogisticRegression(),\n","\t# SVC(),\n","\t# DecisionTreeClassifier()\n","]\n","\n","# Crea un diccionario para almacenar los resultados.\n","results_dict={\n","\t'Model Name':[],\n","\t'DataFrame':[],\n","\t'Cross Validation':[]\n","}\n","\n","# Para cada modelo y tipo de procesamiento de texto, realiza el entrenamiento y la evaluación.\n","for model in models:\n","\tfor embedding_vector in text_embedding.keys():\n","\t\tX_train = text_embedding[embedding_vector][0]\n","\t\tX_test = text_embedding[embedding_vector][1]\n","\t\ty_train = text_embedding[embedding_vector][2]\n","\t\ty_test = text_embedding[embedding_vector][3]\n","\n","\t\twith tf.device('/gpu:0'): # Utiliza la GPU para acelerar el entrenamiento si está disponible.\n","\t\t\tmodel.fit(X_train, y_train)\n","\n","\t\tresults_dict['Model Name'].append(type(model).__name__)\n","\t\tresults_dict['DataFrame'].append(embedding_vector)\n","\n","\t\twith tf.device('/gpu:0'): # Utiliza la GPU para acelerar la evaluación si está disponible.\n","\t\t\tscores = cross_val_score(model, X_test, y_test, cv=5)\n","\t\t\tresults_dict['Cross Validation'].append(scores.mean())\n","\n","# Crea un DataFrame con los resultados.\n","with tf.device('/gpu:0'): # Utiliza la GPU para acelerar la creación del DataFrame si está disponible.\n","\tresults_df=pd.DataFrame(results_dict)\n","\n","results_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3826042,"status":"ok","timestamp":1687303349591,"user":{"displayName":"Sebastian Ruiz Uvalle","userId":"09308680691368063451"},"user_tz":360},"id":"fWWBBVHdgkJm","outputId":"5cf95930-b5e7-42e5-9e1b-26cbf409f4c5"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","  <div id=\"df-262502e2-6f9c-40c6-9bce-47849fee2ff9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model Name</th>\n","      <th>Embedding type</th>\n","      <th>Cross Validation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>SVC</td>\n","      <td>none</td>\n","      <td>0.598443</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>SVC</td>\n","      <td>stemming</td>\n","      <td>0.589325</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>SVC</td>\n","      <td>lematization</td>\n","      <td>0.597338</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>SVC</td>\n","      <td>both</td>\n","      <td>0.590259</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-262502e2-6f9c-40c6-9bce-47849fee2ff9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-262502e2-6f9c-40c6-9bce-47849fee2ff9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-262502e2-6f9c-40c6-9bce-47849fee2ff9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["  Model Name Embedding type  Cross Validation\n","0        SVC           none          0.598443\n","1        SVC       stemming          0.589325\n","2        SVC   lematization          0.597338\n","3        SVC           both          0.590259"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# from sklearn.linear_model import LogisticRegression\n","# from sklearn.svm import SVC\n","# from sklearn.tree import DecisionTreeClassifier\n","# from sklearn.model_selection import cross_val_score\n","\n","# Siendo las mismas instrucciones para los comentarios del funcionamiento recurra a la anterior seccion\n","\n","text_embedding = {\n","\t'none':(X_tfidf_none_train, X_tfidf_none_test, y_none_train, y_none_test),\n","\t'stemming':(X_tfidf_stemming_train, X_tfidf_stemming_test, y_stemming_train, y_stemming_test),\n","\t'lematization':(X_tfidf_lematization_train, X_tfidf_lematization_test, y_lematization_train, y_lematization_test),\n","\t'both':(X_tfidf_both_train, X_tfidf_both_test, y_both_train, y_both_test)\n","}\n","\n","models = [\n","\t# LogisticRegression(),\n","\tSVC(kernel='linear', max_iter=1000),\n","\t# DecisionTreeClassifier()\n","]\n","\n","results_dict={\n","\t'Model Name':[],\n","\t'Embedding type':[],\n","\t'Cross Validation':[]\n","}\n","\n","for model in models:\n","\tfor embedding_vector in text_embedding.keys():\n","\t\tX_train = text_embedding[embedding_vector][0]\n","\t\tX_test = text_embedding[embedding_vector][1]\n","\t\ty_train = text_embedding[embedding_vector][2]\n","\t\ty_test = text_embedding[embedding_vector][3]\n","\n","\t\twith tf.device('/gpu:0'):\n","\t\t\tmodel.fit(X_train, y_train)\n","\n","\t\tresults_dict['Model Name'].append(type(model).__name__)\n","\t\tresults_dict['Embedding type'].append(embedding_vector)\n","\n","\t\twith tf.device('/gpu:0'):\n","\t\t\tscores = cross_val_score(model, X_test, y_test, cv=5)\n","\t\t\tresults_dict['Cross Validation'].append(scores.mean())\n","\n","with tf.device('/gpu:0'):\n","\tresults_df=pd.DataFrame(results_dict)\n","\n","results_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"elapsed":156,"status":"ok","timestamp":1687303550538,"user":{"displayName":"Sebastian Ruiz Uvalle","userId":"09308680691368063451"},"user_tz":360},"id":"HQcCj4KaH0dx","outputId":"ba273dd0-3f1d-4e63-aa82-85cec416955f"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-0eed7e93-783f-435d-85c1-baef3e83a1a0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model Name</th>\n","      <th>DataFrame</th>\n","      <th>Cross Validation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>SVC</td>\n","      <td>none</td>\n","      <td>0.598443</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>SVC</td>\n","      <td>stemming</td>\n","      <td>0.589325</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>SVC</td>\n","      <td>lematization</td>\n","      <td>0.597338</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>SVC</td>\n","      <td>both</td>\n","      <td>0.590259</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0eed7e93-783f-435d-85c1-baef3e83a1a0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0eed7e93-783f-435d-85c1-baef3e83a1a0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0eed7e93-783f-435d-85c1-baef3e83a1a0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["  Model Name     DataFrame  Cross Validation\n","0        SVC          none          0.598443\n","1        SVC      stemming          0.589325\n","2        SVC  lematization          0.597338\n","3        SVC          both          0.590259"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Renombra la columna 'Embedding type' por 'DataFrame'\n","results_df.rename(columns = {'Embedding type':'DataFrame'}, inplace = True)\n","# Muestra los datos de 'results_df'\n","results_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0JOYsxWgkJm","outputId":"13e24bc0-30c7-491f-f185-178dce2174bf"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model Name</th>\n","      <th>Embedding type</th>\n","      <th>Cross Validation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DecisionTreeClassifier</td>\n","      <td>none</td>\n","      <td>0.558460</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>DecisionTreeClassifier</td>\n","      <td>stemming</td>\n","      <td>0.563132</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>DecisionTreeClassifier</td>\n","      <td>lematization</td>\n","      <td>0.554439</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>DecisionTreeClassifier</td>\n","      <td>both</td>\n","      <td>0.562254</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Model Name Embedding type  Cross Validation\n","0  DecisionTreeClassifier           none          0.558460\n","1  DecisionTreeClassifier       stemming          0.563132\n","2  DecisionTreeClassifier   lematization          0.554439\n","3  DecisionTreeClassifier           both          0.562254"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# from sklearn.linear_model import LogisticRegression\n","# from sklearn.svm import SVC\n","# from sklearn.tree import DecisionTreeClassifier\n","# from sklearn.model_selection import cross_val_score\n","\n","# Siendo las mismas instrucciones para los comentarios del funcionamiento recurra a la anterior seccion\n","\n","text_embedding = {\n","\t'none':(X_tfidf_none_train, X_tfidf_none_test, y_none_train, y_none_test),\n","\t'stemming':(X_tfidf_stemming_train, X_tfidf_stemming_test, y_stemming_train, y_stemming_test),\n","\t'lematization':(X_tfidf_lematization_train, X_tfidf_lematization_test, y_lematization_train, y_lematization_test),\n","\t'both':(X_tfidf_both_train, X_tfidf_both_test, y_both_train, y_both_test)\n","}\n","\n","models = [\n","\t# LogisticRegression(),\n","\t# SVC(),\n","\tDecisionTreeClassifier()\n","]\n","\n","results_dict={\n","\t'Model Name':[],\n","\t'Embedding type':[],\n","\t'Cross Validation':[]\n","}\n","\n","for model in models:\n","\tfor embedding_vector in text_embedding.keys():\n","\t\tX_train = text_embedding[embedding_vector][0]\n","\t\tX_test = text_embedding[embedding_vector][1]\n","\t\ty_train = text_embedding[embedding_vector][2]\n","\t\ty_test = text_embedding[embedding_vector][3]\n","\n","\t\twith tf.device('/gpu:0'):\n","\t\t\tmodel.fit(X_train, y_train)\n","\n","\t\tresults_dict['Model Name'].append(type(model).__name__)\n","\t\tresults_dict['Embedding type'].append(embedding_vector)\n","\n","\t\twith tf.device('/gpu:0'):\n","\t\t\tscores = cross_val_score(model, X_test, y_test, cv=5)\n","\t\t\tresults_dict['Cross Validation'].append(scores.mean())\n","with tf.device('/gpu:0'):\n","\tresults_df=pd.DataFrame(results_dict)\n","\n","results_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FMPAS-ongkJn","outputId":"3cca62e9-6720-42a1-f25a-9d2d3a0f7e5c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model Name</th>\n","      <th>DataFrame</th>\n","      <th>Cross Validation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DecisionTreeClassifier</td>\n","      <td>none</td>\n","      <td>0.558460</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>DecisionTreeClassifier</td>\n","      <td>stemming</td>\n","      <td>0.563132</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>DecisionTreeClassifier</td>\n","      <td>lematization</td>\n","      <td>0.554439</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>DecisionTreeClassifier</td>\n","      <td>both</td>\n","      <td>0.562254</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Model Name     DataFrame  Cross Validation\n","0  DecisionTreeClassifier          none          0.558460\n","1  DecisionTreeClassifier      stemming          0.563132\n","2  DecisionTreeClassifier  lematization          0.554439\n","3  DecisionTreeClassifier          both          0.562254"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Renombra la columna 'Embedding type' por 'DataFrame'\n","results_df.rename(columns = {'Embedding type':'DataFrame'}, inplace = True)\n","# Muestra los datos de 'results_df'\n","results_df"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6911,"status":"ok","timestamp":1687318217320,"user":{"displayName":"Sebastian Ruiz Uvalle","userId":"09308680691368063451"},"user_tz":360},"id":"CoD3OqHvM8HP","outputId":"0791edcb-af30-4d1d-dc3d-d19e62da6fae"},"outputs":[{"name":"stdout","output_type":"stream","text":["[ 59764 104664  58659 ...  52267 112294  76905]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n","[26081  8914 15540 ... 21331 24490 17424]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n","----------------------------------------------\n","[ 59731 104613  58628 ...  52551 112200  76869]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n","[26082  8930 15363 ... 21331 24488 17421]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n","----------------------------------------------\n","[ 59731 104613  58626 ...  52547 112248  76869]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n","[26082  8929 15363 ... 21329 24488 17421]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n","----------------------------------------------\n","[ 59731 104613  58628 ...  52551 112200  76869]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n","[26082  8930 15363 ... 21331 24488 17421]\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]}],"source":["from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# El siguiente código utiliza LabelEncoder para codificar variables categóricas\n","# y OneHotEncoder para aplicar codificación one-hot.\n","# para X_none_train\n","encoded = LabelEncoder().fit_transform(X_none_train)\n","print(encoded)\n","\n","encoded = encoded.reshape(len(encoded), 1)\n","oneHot_none_train = OneHotEncoder(sparse=False).fit_transform(encoded)\n","print(oneHot_none_train)\n","\n","# para X_none_test\n","encoded = LabelEncoder().fit_transform(X_none_test)\n","print(encoded)\n","\n","encoded = encoded.reshape(len(encoded), 1)\n","oneHot_none_test = OneHotEncoder(sparse=False).fit_transform(encoded)\n","print(oneHot_none_test)\n","\n","\n","print(\"----------------------------------------------\")\n","# X_stemming_train\n","encoded = LabelEncoder().fit_transform(X_stemming_train)\n","print(encoded)\n","\n","encoded = encoded.reshape(len(encoded), 1)\n","oneHot_stemming_train = OneHotEncoder(sparse=False).fit_transform(encoded)\n","print(oneHot_stemming_train)\n","\n","# para X_stemming_test\n","encoded = LabelEncoder().fit_transform(X_stemming_test)\n","print(encoded)\n","\n","encoded = encoded.reshape(len(encoded), 1)\n","oneHot_stemming_test = OneHotEncoder(sparse=False).fit_transform(encoded)\n","print(oneHot_stemming_test)\n","\n","\n","print(\"----------------------------------------------\")\n","# X_lematization_train\n","encoded = LabelEncoder().fit_transform(X_lematization_train)\n","print(encoded)\n","\n","encoded = encoded.reshape(len(encoded), 1)\n","oneHot_lematization_train = OneHotEncoder(sparse=False).fit_transform(encoded)\n","print(oneHot_lematization_train)\n","\n","# para X_lematization_test\n","encoded = LabelEncoder().fit_transform(X_lematization_test)\n","print(encoded)\n","\n","encoded = encoded.reshape(len(encoded), 1)\n","oneHot_lematization_test = OneHotEncoder(sparse=False).fit_transform(encoded)\n","print(oneHot_lematization_test)\n","\n","\n","print(\"----------------------------------------------\")\n","# X_both_train\n","encoded = LabelEncoder().fit_transform(X_both_train)\n","print(encoded)\n","\n","encoded = encoded.reshape(len(encoded), 1)\n","oneHot_both_train = OneHotEncoder(sparse=False).fit_transform(encoded)\n","print(oneHot_both_train)\n","\n","# para X_both_test\n","encoded = LabelEncoder().fit_transform(X_both_test)\n","print(encoded)\n","\n","encoded = encoded.reshape(len(encoded), 1)\n","oneHot_both_test = OneHotEncoder(sparse=False).fit_transform(encoded)\n","print(oneHot_both_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_z1KG_Zb9wOw"},"outputs":[],"source":["# Esta seccion no se logro que funcionara por problemas de utilizacion de la memoria del servidor\n","\n","# import pandas as pd\n","# from sklearn.preprocessing import OneHotEncoder\n","# from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Flatten, Dense\n","\n","# df_none = pd.read_csv(r'/content/drive/MyDrive/none.csv')\n","# df_stemming = pd.read_csv(r'/content/drive/MyDrive/stemming.csv')\n","# df_lematization = pd.read_csv(r'/content/drive/MyDrive/lematization.csv')\n","# df_both = pd.read_csv(r'/content/drive/MyDrive/both.csv')\n","\n","model = Sequential()\n","model.add(Embedding(input_dim=oneHot_none_train.shape[1], output_dim=64, input_length=1))  # Embedding layer\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","model.fit(oneHot_none_train, y_none_train, epochs=10, batch_size=32)\n","loss, accuracy = model.evaluate(oneHot_none_test, y_none_test)\n","print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1Zy1KqM08m9rNfi5mFtDgSDeHCDBRiFI-","timestamp":1687293171657}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
